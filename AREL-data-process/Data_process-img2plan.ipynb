{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \".\"\n",
    "train_data = json.load(open(osp.join(\"train.story-in-sequence.json\")))\n",
    "val_data = json.load(open(osp.join(\"val.story-in-sequence.json\")))\n",
    "test_data = json.load(open(osp.join(\"test.story-in-sequence.json\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = [\"train\", \"val\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/root/xhong/VStorytelling/Coherent_VStorytelling/kemhra/vist/data/plan/test0_src.txt'\n",
    "train_path = '/root/xhong/VStorytelling/Coherent_VStorytelling/kemhra/vist/data/plan/train_src.txt'\n",
    "val_path = '/root/xhong/VStorytelling/Coherent_VStorytelling/kemhra/vist/data/plan/val0_src.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in prefix:\n",
    "    src_path = eval(p + '_path')\n",
    "    with open(src_path, 'r') as f:\n",
    "        src_dict[p] = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(line_list):\n",
    "    story_dict = defaultdict(list)\n",
    "    for line in line_list:\n",
    "        tokens = line.split()\n",
    "        story_id = tokens[0]\n",
    "        sentences = line.split('<S>')\n",
    "        sentences[0] = sentences[0].replace(story_id + ' ', '')\n",
    "        if len(sentences) != 5:\n",
    "            continue\n",
    "        # print ('len(sentences)', len(sentences))\n",
    "        for sent in sentences:\n",
    "            story_dict[story_id].append(sent)\n",
    "    return story_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print test_data[\"annotations\"][i][0]\n",
    "#     print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_plan_dict = {}\n",
    "for p in prefix:\n",
    "    story_plan_dict[p] = get_dict(src_dict[p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36532\n",
      "4515\n",
      "4591\n"
     ]
    }
   ],
   "source": [
    "for p in prefix:\n",
    "    print len(story_plan_dict[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<V> arrived <A1> My sister <V> help <A0> My sister <A1> with the family Bar BQ <A2> me ',\n",
       " '  <V> arrived <A1> Every one else ',\n",
       " '  <V> manned <A0> Dad <A1> the grill ',\n",
       " '  <V> was <A1> so much food <V> was <A1> it <A2> delicious ',\n",
       " '  \\n']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dict['40470']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228190\n",
      "45638\n",
      "9362\n"
     ]
    }
   ],
   "source": [
    "whole_album2im = {}\n",
    "for i, data in enumerate([train_data, val_data, test_data]):\n",
    "    album2im = {}\n",
    "    for im in data['images']:\n",
    "        if im['album_id'] not in album2im:\n",
    "            album2im[im['album_id']] = [im['id']]\n",
    "        else:\n",
    "            if im['id'] not in album2im[im['album_id']]:\n",
    "                album2im[im['album_id']].append(im['id'])\n",
    "    whole_album2im[prefix[i]] = album2im\n",
    "\n",
    "whole_album = {}\n",
    "story_lines = {}\n",
    "whole_lines = {}\n",
    "story_line_count = 0\n",
    "whole_line_count = 0\n",
    "for i, data in enumerate([train_data, val_data, test_data]):\n",
    "    p = prefix[i]\n",
    "    story_plans = story_plan_dict[p]\n",
    "    album_mapping = {}\n",
    "    for annot_new in data[\"annotations\"]:\n",
    "        annot = annot_new[0]\n",
    "        assert len(annot_new) == 1\n",
    "        \n",
    "        story_id = annot['story_id']\n",
    "        photo_order = annot['worker_arranged_photo_order']\n",
    "        \n",
    "        story_plan = story_plans[story_id]\n",
    "        if len(story_plan) != 5:\n",
    "            continue\n",
    "            \n",
    "        sentence_plan = story_plan[int(photo_order)]\n",
    "        \n",
    "        # change the text here!\n",
    "        text = sentence_plan\n",
    "        \n",
    "        if annot['story_id'] not in album_mapping:\n",
    "            album_mapping[annot['story_id']] = {\"text_index\": [story_line_count], \"flickr_id\": [annot['photo_flickr_id']], \"length\": 1, \n",
    "                                                \"album_id\": annot['album_id'], \"album_flickr_id\": whole_album2im[prefix[i]][annot['album_id']],\n",
    "                                                \"whole_text_index\": whole_line_count, \"origin_text\": text}\n",
    "            story_lines[annot['story_id']] = [{\"index\": story_line_count, \"text\": text.split()}]\n",
    "            whole_lines[annot['story_id']] = {\"index\": whole_line_count, \"text\": text.split()}\n",
    "            whole_line_count +=1\n",
    "        else:\n",
    "            album_mapping[annot['story_id']][\"text_index\"].append(story_line_count)\n",
    "            album_mapping[annot['story_id']][\"flickr_id\"].append(annot['photo_flickr_id'])\n",
    "            album_mapping[annot['story_id']][\"length\"] += 1\n",
    "            story_lines[annot['story_id']].append({\"index\": story_line_count, \"text\": text.split()})\n",
    "            whole_lines[annot['story_id']][\"text\"].extend(text.split())\n",
    "            album_mapping[annot['story_id']][\"origin_text\"] += \" \" + text \n",
    "        story_line_count += 1\n",
    "    whole_album[prefix[i]] = album_mapping\n",
    "\n",
    "new_story_lines = [] \n",
    "for l in story_lines.values():\n",
    "    for li in l:\n",
    "        new_story_lines.append(li)\n",
    "story_lines = new_story_lines\n",
    "whole_lines = whole_lines.values()\n",
    "\n",
    "story_lines = [r['text'] for r in sorted(story_lines, key=lambda thing: thing['index'])]\n",
    "whole_lines = [r['text'] for r in sorted(whole_lines, key=lambda thing: thing['index'])]\n",
    "\n",
    "print len(story_lines)\n",
    "print len(whole_lines)\n",
    "\n",
    "from collections import Counter\n",
    "import numpy\n",
    "cnt = Counter()\n",
    "for l in story_lines:\n",
    "    words = l\n",
    "    for w in words:\n",
    "        cnt[w] += 1\n",
    "words2id = {}\n",
    "idx = 2\n",
    "for k, v in cnt.most_common():\n",
    "    if v > 5:\n",
    "        words2id[k] = idx\n",
    "        idx += 1\n",
    "words2id[\"<EOS>\"] = 0\n",
    "words2id[\"<UNK>\"] = 1\n",
    "id2words = {v:k for k,v in words2id.iteritems()}\n",
    "print len(id2words)\n",
    "\n",
    "whole_album[\"words2id\"] = words2id\n",
    "whole_album[\"id2words\"] = {v:k for k,v in words2id.iteritems()}\n",
    "\n",
    "id_story_lines = []\n",
    "for l in story_lines:\n",
    "    s = [words2id[w] if w in words2id else 1 for w in l]\n",
    "    id_story_lines.append(s)\n",
    "\n",
    "id_whole_lines = []\n",
    "for l in whole_lines:\n",
    "    s = [words2id[w] if w in words2id else 1 for w in l]\n",
    "    id_whole_lines.append(s)\n",
    "\n",
    "new_id_whole_lines = []\n",
    "specify_longest = 105\n",
    "for i in range(len(id_whole_lines)):\n",
    "    cur_len = len(id_whole_lines[i])\n",
    "    if cur_len < specify_longest:\n",
    "        new_id_whole_lines.append(id_whole_lines[i] + [0] * (specify_longest - cur_len))\n",
    "    else:\n",
    "        new_id_whole_lines.append(id_whole_lines[i][:specify_longest-1] + [0])\n",
    "\n",
    "data = numpy.asarray(new_id_whole_lines)\n",
    "import h5py\n",
    "f = h5py.File(\"full_story.h5\", \"w\")\n",
    "f.create_dataset(\"story\", data=data)\n",
    "f.close()\n",
    "\n",
    "new_id_story_lines = []\n",
    "specify_longest = 30\n",
    "for i in range(len(id_story_lines)):\n",
    "    cur_len = len(id_story_lines[i])\n",
    "    if cur_len < specify_longest:\n",
    "        new_id_story_lines.append(id_story_lines[i] + [0] * (specify_longest - cur_len))\n",
    "    else:\n",
    "        new_id_story_lines.append(id_story_lines[i][:specify_longest-1] + [0])\n",
    "\n",
    "data = numpy.asarray(new_id_story_lines, \"int32\")\n",
    "import h5py\n",
    "f = h5py.File(\"story.h5\", \"w\")\n",
    "f.create_dataset(\"story\", data=data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting 38600\n",
      "deleting 38602\n",
      "deleting 38603\n",
      "deleting 8085\n",
      "deleting 8080\n",
      "deleting 8081\n",
      "deleting 8082\n",
      "deleting 8083\n",
      "deleting 8089\n",
      "deleting 7462\n",
      "deleting 7464\n",
      "deleting 36709\n",
      "deleting 36708\n",
      "deleting 36707\n",
      "deleting 36706\n",
      "deleting 36705\n",
      "deleting 18994\n",
      "deleting 18992\n",
      "deleting 18993\n",
      "deleting 18990\n",
      "deleting 18991\n",
      "deleting 36659\n",
      "deleting 36658\n",
      "deleting 36655\n",
      "deleting 36656\n",
      "deleting 8053\n",
      "deleting 8052\n",
      "deleting 8051\n",
      "deleting 8050\n",
      "deleting 8054\n",
      "deleting 36756\n",
      "deleting 36757\n",
      "deleting 8020\n",
      "deleting 8024\n",
      "deleting 24331\n",
      "deleting 24333\n",
      "deleting 24332\n",
      "deleting 24334\n",
      "deleting 18610\n",
      "deleting 25587\n",
      "deleting 25586\n",
      "deleting 25588\n",
      "deleting 33059\n",
      "deleting 33055\n",
      "deleting 33056\n",
      "deleting 33057\n",
      "deleting 7388\n",
      "deleting 7389\n",
      "deleting 7387\n",
      "deleting 7385\n",
      "deleting 41915\n",
      "deleting 41919\n",
      "deleting 49044\n",
      "deleting 49043\n",
      "deleting 49040\n",
      "deleting 49041\n"
     ]
    }
   ],
   "source": [
    "for p in prefix:\n",
    "    path = \"/root/xhong/VStorytelling/AREL/database/resnet_features/fc/{}/\".format(p)\n",
    "    deletables = []\n",
    "    for story_id, story in whole_album[p].iteritems():\n",
    "        d = [osp.exists(osp.join(path, \"{}.npy\".format(_))) for _ in story[\"flickr_id\"]]\n",
    "        if sum(d) < 5:\n",
    "            print \"deleting {}\".format(story_id)\n",
    "            deletables.append(story_id)\n",
    "        else:\n",
    "            pass\n",
    "    for i in deletables:\n",
    "        del whole_album[p][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_story_map = {}\n",
    "for pre in prefix:\n",
    "    album = whole_album[pre]\n",
    "    for k, v in album.iteritems():\n",
    "        indexes = v['text_index']\n",
    "        for i, flickr_id in enumerate(v['flickr_id']):\n",
    "            if flickr_id not in flickr_story_map:\n",
    "                flickr_story_map[flickr_id] = [indexes[i]]\n",
    "            else:\n",
    "                flickr_story_map[flickr_id].append(indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAD4hJREFUeJzt3X+s3Xddx/Hni3YdBuYm9mKWtaWdlkhDCFuuGwkGUaZ206yaoOkSI5qFJkr9EdBYgplzxkQgSkJSwRrn+KGUgT9otGQQGMEYN9bJNtbVwnVMd+1CB4wpITCmb/84346z23PvPffe055z7uf5SG7u9/s9n3vuK5+cvva9n3O+36WqkCStb88ZdwBJ0rln2UtSAyx7SWqAZS9JDbDsJakBlr0kNcCyl6QGWPaS1ADLXpIasHFcv3jz5s21ffv2cf16SZpK995775eramalPze2st++fTvHjh0b16+XpKmU5D9W83Mu40hSAyx7SWqAZS9JDbDsJakBlr0kNWDZsk9ya5LTSR5c5PEkeWeSuSQPJLly9DElSWsxzJn9bcDuJR6/FtjZfe0D3rX2WJKkUVq27Kvq08BXlxiyB3hv9dwFXJLk0lEFlCSt3SjW7C8DHu3bn++OSZImxCiuoM2AYwP/L+ZJ9tFb6mHbtm0j+NXrwM0XjzvB+nfzk6v6se0H/nHEQaSeR/7op8777xxF2c8DW/v2twCnBg2sqkPAIYDZ2dmB/0FYlyz0sbK0pdGU/RFgf5LDwNXAk1X12AiedzpZ7JIm0LJln+QDwKuBzUnmgd8DLgCoqncDR4HrgDngG8Avn6uwE82SlzTBli37qrphmccLeMPIEk0bS17SFPAK2rWw6CVNibHdz36qWfKSpoxn9itl0UuaQpb9Slj0kqaUZT8si17SFLPsh2HRS5pylv1yLHpJ64BlL0kNsOyX4lm9pHXCsl+MRS9pHbHsJakBlr0kNcCyl6QGWPaDuF4vaZ2x7CWpAZb9Qp7VS1qHLHtJaoBlL0kNsOz7uYQjaZ2y7CWpAZa9JDXAsj/DJRxJ65hlL0kNsOwlqQGWPbiEI2nds+wlqQGWvSQ1wLJ3CUdSAyx7SWqAZS9JDbDsJakBbZe96/WSGjFU2SfZneRkkrkkBwY8vi3JnUk+m+SBJNeNPqokabWWLfskG4CDwLXALuCGJLsWDPtd4PaqugLYC/zpqINKklZvmDP7q4C5qnq4qp4CDgN7Fowp4Lu77YuBU6OLKElaq41DjLkMeLRvfx64esGYm4GPJfk14HnANSNJdy65Xi+pIcOc2WfAsVqwfwNwW1VtAa4D3pfkrOdOsi/JsSTHHn/88ZWnlSStyjBlPw9s7dvfwtnLNDcCtwNU1b8AzwU2L3yiqjpUVbNVNTszM7O6xJKkFRum7O8BdibZkWQTvTdgjywY85/AawCSvIRe2XvqLkkTYtmyr6qngf3AHcAJep+6OZ7kliTXd8PeBLw+yf3AB4BfqqqFSz2SpDEZ5g1aquoocHTBsZv6th8CXjnaaJKkUWn7ClpJaoRlL0kNsOwlqQGWvSQ1oM2y9+pZSY1ps+wlqTGWvSQ1wLKXpAZY9pLUAMtekhrQXtn7SRxJDWqv7CWpQZa9JDXAspekBlj2ktQAy16SGtBW2ftJHEmNaqvsJalRlr0kNcCyl6QGWPaS1ADLXpIaYNlLUgPaKXs/dimpYe2UvSQ1zLKXpAZY9pLUAMtekhpg2UtSAyx7SWpAG2Xvxy4lNa6Nspekxln2ktSAoco+ye4kJ5PMJTmwyJifT/JQkuNJ/nq0MSVJa7FxuQFJNgAHgR8H5oF7khypqof6xuwE3gy8sqqeSPLCcxVYkrRyw5zZXwXMVdXDVfUUcBjYs2DM64GDVfUEQFWdHm1MSdJaDFP2lwGP9u3Pd8f6vRh4cZJ/TnJXkt2jCihJWrtll3GADDhWA55nJ/BqYAvwT0leWlVfe9YTJfuAfQDbtm1bcdhV8WOXkjTUmf08sLVvfwtwasCYj1TVt6vqi8BJeuX/LFV1qKpmq2p2ZmZmtZklSSs0TNnfA+xMsiPJJmAvcGTBmL8HfhQgyWZ6yzoPjzKoJGn1li37qnoa2A/cAZwAbq+q40luSXJ9N+wO4CtJHgLuBH67qr5yrkJLklZmmDV7quoocHTBsZv6tgt4Y/clSZowXkErSQ2w7CWpAZa9JDVgfZe9n7GXJGC9l70kCbDsJakJlr0kNcCyl6QGWPaS1ADLXpIaYNlLUgMse0lqwPotey+okqRnrN+ylyQ9w7KXpAZY9pLUAMtekhpg2UtSAyx7SWqAZS9JDbDsJakBlr0kNcCyl6QGrM+y91YJkvQs67PsJUnPYtlLUgMse0lqgGUvSQ2w7CWpAZa9JDXAspekBlj2ktSAoco+ye4kJ5PMJTmwxLjXJqkks6OLKElaq2XLPskG4CBwLbALuCHJrgHjLgJ+Hbh71CElSWszzJn9VcBcVT1cVU8Bh4E9A8b9AfA24JsjzLdy3ipBks4yTNlfBjzatz/fHXtGkiuArVX1DyPMJkkakWHKPgOO1TMPJs8B3gG8adknSvYlOZbk2OOPPz58SknSmgxT9vPA1r79LcCpvv2LgJcCn0ryCPAK4MigN2mr6lBVzVbV7MzMzOpTS5JWZJiyvwfYmWRHkk3AXuDImQer6smq2lxV26tqO3AXcH1VHTsniSVJK7Zs2VfV08B+4A7gBHB7VR1PckuS6891QEnS2m0cZlBVHQWOLjh20yJjX732WJKkUfIKWklqgGUvSQ2w7CWpAZa9JDXAspekBlj2ktQAy16SGmDZS1IDLHtJaoBlL0kNsOwlqQGWvSQ1wLKXpAZY9pLUAMtekhpg2UtSAyx7SWqAZS9JDVhfZX/zxeNOIEkTaX2VvSRpIMtekhpg2UtSAyx7SWqAZS9JDbDsJakBlr0kNcCyl6QGWPaS1ID1U/ZePStJi1o/ZS9JWtT6KHvP6iVpSeuj7CVJS7LsJakBQ5V9kt1JTiaZS3JgwONvTPJQkgeSfCLJi0YfVZK0WsuWfZINwEHgWmAXcEOSXQuGfRaYraqXAR8G3jbqoJKk1RvmzP4qYK6qHq6qp4DDwJ7+AVV1Z1V9o9u9C9gy2piSpLXYOMSYy4BH+/bngauXGH8j8NFBDyTZB+wD2LZt25ARB/DTN5K0IsOc2WfAsRo4MPkFYBZ4+6DHq+pQVc1W1ezMzMzwKSVJazLMmf08sLVvfwtwauGgJNcAbwF+pKq+NZp4kqRRGObM/h5gZ5IdSTYBe4Ej/QOSXAH8GXB9VZ0efUxJ0losW/ZV9TSwH7gDOAHcXlXHk9yS5Ppu2NuB5wMfSnJfkiOLPJ0kaQyGWcahqo4CRxccu6lv+5oR55IkjZBX0EpSAyx7SWqAZS9JDbDsJakBlr0kNcCyl6QGWPaS1ADLXpIaYNlLUgMse0lqgGUvSQ2w7CWpAZa9JDXAspekBlj2ktQAy16SGmDZS1IDLHtJaoBlL0kNsOwlqQGWvSQ1wLKXpAZY9pLUAMtekhpg2UtSAyx7SWqAZS9JDbDsJakBlr0kNcCyl6QGWPaS1ADLXpIaMFTZJ9md5GSSuSQHBjx+YZIPdo/fnWT7qINKklZv2bJPsgE4CFwL7AJuSLJrwbAbgSeq6geAdwBvHXVQSdLqDXNmfxUwV1UPV9VTwGFgz4Ixe4D3dNsfBl6TJKOLKUlai2HK/jLg0b79+e7YwDFV9TTwJPC9owgoSVq7jUOMGXSGXqsYQ5J9wL5u9+tJTg7x+wfZDHx5lT87TtOYexozw7Ny//RYg6zANM71NGaGMefO6ha6z2R+0Wp+eJiynwe29u1vAU4tMmY+yUbgYuCrC5+oqg4Bh1YTtF+SY1U1u9bnOd+mMfc0ZobpzG3m82cac6818zDLOPcAO5PsSLIJ2AscWTDmCPC6bvu1wCer6qwze0nSeCx7Zl9VTyfZD9wBbABurarjSW4BjlXVEeAvgPclmaN3Rr/3XIaWJK3MMMs4VNVR4OiCYzf1bX8T+LnRRlvSmpeCxmQac09jZpjO3GY+f6Yx95oyx9UWSVr/vF2CJDVg6sp+uVs3TIokjyT5XJL7khzrjr0gyceTfKH7/j0TkPPWJKeTPNh3bGDO9Lyzm/sHklw5QZlvTvJf3Xzfl+S6vsfe3GU+meQnx5R5a5I7k5xIcjzJb3THJ32uF8s9sfOd5LlJPpPk/i7z73fHd3S3c/lCd3uXTd3xibjdyxK5b0vyxb65fnl3fGWvkaqami96bxD/O3A5sAm4H9g17lyLZH0E2Lzg2NuAA932AeCtE5DzVcCVwIPL5QSuAz5K77qKVwB3T1Dmm4HfGjB2V/c6uRDY0b1+Nowh86XAld32RcDnu2yTPteL5Z7Y+e7m7Pnd9gXA3d0c3g7s7Y6/G/iVbvtXgXd323uBD45prhfLfRvw2gHjV/QambYz+2Fu3TDJ+m8r8R7gZ8aYBYCq+jRnXxOxWM49wHur5y7gkiSXnp+k37FI5sXsAQ5X1beq6ovAHL3X0XlVVY9V1b922/8DnKB35fmkz/ViuRcz9vnu5uzr3e4F3VcBP0bvdi5w9lyP/XYvS+RezIpeI9NW9sPcumFSFPCxJPemd+UwwPdV1WPQ+0cEvHBs6Za2WM5Jn//93Z+zt/YtkU1c5m6Z4Ap6Z25TM9cLcsMEz3eSDUnuA04DH6f3F8bXqnc7l4W5JuZ2LwtzV9WZuf7Dbq7fkeTC7tiK5nrayn6o2zJMiFdW1ZX07hb6hiSvGnegEZjk+X8X8P3Ay4HHgD/ujk9U5iTPB/4G+M2q+u+lhg44Nkm5J3q+q+p/q+rl9K74vwp4yaBh3feJyAxn507yUuDNwA8CPwS8APidbviKck9b2Q9z64aJUFWnuu+ngb+j94L70pk/s7rvp8eXcEmL5ZzY+a+qL3X/UP4P+HO+s3QwMZmTXECvMP+qqv62Ozzxcz0o9zTMN0BVfQ34FL017UvSu53LwlzPZM4St3s5n/py7+6W0qqqvgX8Jauc62kr+2Fu3TB2SZ6X5KIz28BPAA/y7NtKvA74yHgSLmuxnEeAX+w+BfAK4MkzSxDjtmCt8mfpzTf0Mu/tPnGxA9gJfGYM+ULvSvMTVfUnfQ9N9FwvlnuS5zvJTJJLuu3vAq6h917DnfRu5wJnz/XYb/eySO5/6zsZCL33GfrnevjXyDjedV7LF713oD9Pbw3uLePOs0jGy+l9IuF+4PiZnPTWAT8BfKH7/oIJyPoBen+Gf5vemcKNi+Wk92fjwW7uPwfMTlDm93WZHuj+EVzaN/4tXeaTwLVjyvzD9P7EfgC4r/u6bgrmerHcEzvfwMuAz3bZHgRu6o5fTu8/PHPAh4ALu+PP7fbnuscvH9NcL5b7k91cPwi8n+98YmdFrxGvoJWkBkzbMo4kaRUse0lqgGUvSQ2w7CWpAZa9JDXAspekBlj2ktQAy16SGvD/HCUO9SSd7RMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_distribution = [len(s) for s in whole_lines]\n",
    "result = plt.hist(length_distribution, bins='auto', cumulative=True, normed=1)\n",
    "#plt.show()\n",
    "length_distribution = [len(s) for s in story_lines]\n",
    "result = plt.hist(length_distribution, bins='auto', cumulative=True, normed=1)\n",
    "#plt.hist(length_distribution, bins='auto')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "\n",
    "base_dii_path = \"/root/xhong/VStorytelling/SIND/data/dii\"\n",
    "train_dii_data = json.load(open(osp.join(base_path, \"train.description-in-isolation.json\")))\n",
    "val_dii_data = json.load(open(osp.join(base_path, \"val.description-in-isolation.json\")))\n",
    "test_dii_data = json.load(open(osp.join(base_path, \"test.description-in-isolation.json\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown words percent is 0.0339461862123\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "mapping_original = {}\n",
    "text_list = []\n",
    "text_list_count = 0\n",
    "unknown_words = 0\n",
    "total_words = 0\n",
    "with_story = 0\n",
    "no_story = 0\n",
    "for i, data in enumerate([train_dii_data, val_dii_data, test_dii_data]):\n",
    "    mapping[prefix[i]] = {}\n",
    "    mapping_original[prefix[i]] = {}\n",
    "    for l in data['annotations']:\n",
    "        if l[0]['photo_flickr_id'] not in mapping[prefix[i]]:\n",
    "            if l[0]['photo_flickr_id'] in flickr_story_map:\n",
    "                stories =  flickr_story_map[l[0]['photo_flickr_id']]\n",
    "            else:\n",
    "                stories = [-1]\n",
    "            mapping[prefix[i]][l[0]['photo_flickr_id']] = {'caption': [text_list_count], 'story': stories}\n",
    "            mapping_original[prefix[i]][l[0]['photo_flickr_id']] = [l[0]['text']]\n",
    "        else:\n",
    "            mapping[prefix[i]][l[0]['photo_flickr_id']]['caption'].append(text_list_count)\n",
    "            mapping_original[prefix[i]][l[0]['photo_flickr_id']].append(l[0]['text'])\n",
    "        text_list_count += 1\n",
    "        assert len(l) == 1\n",
    "        s = []\n",
    "        for w in l[0]['text'].split(\" \"):\n",
    "            if w in words2id:\n",
    "                s.append(words2id[w])  \n",
    "            else:\n",
    "                s.append(1)\n",
    "                unknown_words += 1\n",
    "            total_words += 1\n",
    "        text_list.append(s)\n",
    "print \"unknown words percent is {}\".format(unknown_words / (total_words + 0.0))\n",
    "new_text_list = []\n",
    "specify_longest = 20\n",
    "for i in range(len(text_list)):\n",
    "    cur_len = len(text_list[i])\n",
    "    if cur_len < specify_longest:\n",
    "        new_text_list.append(text_list[i] + [0] * (specify_longest - cur_len))\n",
    "    else:\n",
    "        new_text_list.append(text_list[i][:specify_longest - 1] + [0]) \n",
    "\n",
    "for p in prefix:\n",
    "    path = \"/root/xhong/VStorytelling/AREL/database/resnet_features/fc/{}/\".format(p)\n",
    "    deletables = []\n",
    "    for flickr_id, story in mapping[p].iteritems():\n",
    "        if not osp.exists(osp.join(path, \"{}.npy\".format(flickr_id))):\n",
    "            deletables.append(flickr_id)\n",
    "    for i in deletables:\n",
    "        del mapping[p][i]\n",
    "        del mapping_original[p][i]\n",
    "        \n",
    "whole_album[\"image2caption\"] = mapping\n",
    "whole_album[\"image2caption_original\"] = mapping_original\n",
    "\n",
    "with open(\"story_line.json\", 'w') as f:\n",
    "    json.dump(whole_album, f)\n",
    "\n",
    "text_array = numpy.asarray(new_text_list, dtype='int32')\n",
    "import h5py\n",
    "f = h5py.File(\"description.h5\", 'w')\n",
    "f.create_dataset(\"story\", data=text_array)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  119    4   84    3   43  340    2   15    2  177    4  108    2\n",
      " 1052    3   45   16    9  759 1763  165    2   16    3   45    6    9\n",
      "  759 1763    2   16    3   14  340    6   41 1412    2 5048    3 3991\n",
      " 4160    2   11    3   14 3693    6  117 1492   42   82  128   82 3761\n",
      "  887    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "(228190, 30)\n",
      "9362\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "\n",
    "# val_data = json.load(open(osp.join(base_path, \"val.description-in-isolation.json\")))\n",
    "\n",
    "with open(\"val_desc_reference\", \"w\") as f:\n",
    "    for l in val_data['annotations']:\n",
    "        print >> f, \"{}\\t{}\".format(l[0]['photo_flickr_id'], l[0]['text'])\n",
    "\n",
    "import h5py\n",
    "f = h5py.File(\"full_story.h5\", \"r\")\n",
    "print f['story'][0]\n",
    "\n",
    "f = h5py.File(\"story.h5\", \"r\")\n",
    "print f['story'].shape\n",
    "\n",
    "f = open(\"story_line.json\", 'r')\n",
    "data = json.load(f)\n",
    "print len(data['id2words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy\n",
    "\n",
    "# zero_fc = numpy.zeros((2048, ), \"float32\")\n",
    "# zero_conv = numpy.zeros((2048, 7, 7), \"float32\")\n",
    "\n",
    "# train_fc_base = \"/mnt/sshd/xwang/VIST/feature/train/fc\"\n",
    "# train_conv_base = \"/mnt/sshd/xwang/VIST/feature/train/conv\"\n",
    "# train_name1 = [l.split(\".\")[0] for l in os.listdir(train_fc_base)]\n",
    "\n",
    "# train_image_base = \"/mnt/sshd/wenhuchen/VIST/images/train\"\n",
    "# train_name2 = [l.split(\".\")[0] for l in os.listdir(train_image_base)]\n",
    "\n",
    "# rest = set(train_name2) - set(train_name1)\n",
    "# for image in rest:\n",
    "#     numpy.save(os.path.join(train_fc_base, \"{}.npy\".format(image)), zero_fc) \n",
    "#     numpy.save(os.path.join(train_conv_base, \"{}.npy\".format(image)), zero_conv) \n",
    "\n",
    "# val_fc_base = \"/mnt/sshd/xwang/VIST/feature/val/fc\"\n",
    "# val_conv_base = \"/mnt/sshd/xwang/VIST/feature/val/conv\"\n",
    "# val_name1 = [l.split(\".\")[0] for l in os.listdir(val_fc_base)]\n",
    "\n",
    "# val_image_base = \"/mnt/sshd/wenhuchen/VIST/images/val\"\n",
    "# val_name2 = [l.split(\".\")[0] for l in os.listdir(val_image_base)]\n",
    "\n",
    "# rest = set(val_name2) - set(val_name1)\n",
    "# for image in rest:\n",
    "#     numpy.save(os.path.join(val_fc_base, \"{}.npy\".format(image)), zero_fc) \n",
    "#     numpy.save(os.path.join(val_conv_base, \"{}.npy\".format(image)), zero_conv) \n",
    "\n",
    "# test_fc_base = \"/mnt/sshd/xwang/VIST/feature/test/fc\"\n",
    "# test_conv_base = \"/mnt/sshd/xwang/VIST/feature/test/conv\"\n",
    "# test_name1 = [l.split(\".\")[0] for l in os.listdir(test_fc_base)]\n",
    "\n",
    "# test_image_base = \"/mnt/sshd/wenhuchen/VIST/images/test\"\n",
    "# test_name2 = [l.split(\".\")[0] for l in os.listdir(test_image_base)]\n",
    "\n",
    "# rest = set(test_name2) - set(test_name1)\n",
    "# for image in rest:\n",
    "#     numpy.save(os.path.join(test_fc_base, \"{}.npy\".format(image)), zero_fc) \n",
    "#     numpy.save(os.path.join(test_conv_base, \"{}.npy\".format(image)), zero_conv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40141\n",
      "36482\n",
      "4513\n",
      "4587\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"story_line.json\", 'r') as f: \n",
    "    data = json.load(f)\n",
    "\n",
    "print len(data['image2caption']['train'])\n",
    "print len(data['train'])\n",
    "print len(data['val'])\n",
    "print len(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'album_flickr_id': [u'694227468',\n",
       "  u'694227344',\n",
       "  u'694227412',\n",
       "  u'694227488',\n",
       "  u'694227508',\n",
       "  u'693397865',\n",
       "  u'693397887',\n",
       "  u'693397911',\n",
       "  u'693397975',\n",
       "  u'693397995',\n",
       "  u'693398013',\n",
       "  u'693413671',\n",
       "  u'693413687',\n",
       "  u'693413703',\n",
       "  u'695160730'],\n",
       " u'album_id': u'72157600601428727',\n",
       " u'flickr_id': [u'693397887',\n",
       "  u'695160730',\n",
       "  u'694227508',\n",
       "  u'693397865',\n",
       "  u'694227468'],\n",
       " u'length': 5,\n",
       " u'origin_text': u'<V> arrived <A1> My sister <V> help <A0> My sister <A1> with the family Bar BQ <A2> me    <V> arrived <A1> Every one else    <V> manned <A0> Dad <A1> the grill    <V> was <A1> so much food <V> was <A1> it <A2> delicious    \\n',\n",
       " u'text_index': [182660, 182661, 182662, 182663, 182664],\n",
       " u'whole_text_index': 36532}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['val']['40470']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
